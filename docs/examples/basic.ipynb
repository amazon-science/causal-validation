{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Data Synthesis\n",
    "\n",
    "In this notebook we'll demonstrate how `causal-validation` can be used to simulate\n",
    "synthetic datasets. We'll start with very simple data to which a static treatment\n",
    "effect may be applied. From there, we'll build up to complex datasets. Along the way,\n",
    "we'll show how reproducibility can be ensured, plots can be generated, and unit-level\n",
    "parameters may be specified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.stats import (\n",
    "    norm,\n",
    "    poisson,\n",
    ")\n",
    "\n",
    "from causal_validation import (\n",
    "    Config,\n",
    "    simulate,\n",
    ")\n",
    "from causal_validation.effects import StaticEffect\n",
    "from causal_validation.plotters import plot\n",
    "from causal_validation.transforms import (\n",
    "    Periodic,\n",
    "    Trend,\n",
    ")\n",
    "from causal_validation.transforms.parameter import UnitVaryingParameter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "## Simulating a Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {
    "title": "Simulating a dataset is as simple as specifying a `Config` object and"
   },
   "source": [
    "then invoking the `simulate` function. Once simulated, we may visualise the data\n",
    "through the `plot` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = Config(\n",
    "    n_control_units=10,\n",
    "    n_pre_intervention_timepoints=60,\n",
    "    n_post_intervention_timepoints=30,\n",
    "    seed=123,\n",
    ")\n",
    "\n",
    "data = simulate(cfg)\n",
    "ax = plot(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "### Controlling baseline behaviour\n",
    "\n",
    "We observe that we have 10 control units, each of which were sampled from a Gaussian\n",
    "distribution with mean 20 and scale 0.2. Had we wished for our underlying observations\n",
    "to have more or less noise, or to have a different global mean, then we can simply\n",
    "specify that through the config file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "means = [10, 50]\n",
    "scales = [0.1, 0.5]\n",
    "\n",
    "fig, axes = plt.subplots(ncols=2, nrows=2, figsize=(10, 6), tight_layout=True)\n",
    "for (m, s), ax in zip(product(means, scales), axes.ravel(), strict=False):\n",
    "    cfg = Config(\n",
    "        n_control_units=10,\n",
    "        n_pre_intervention_timepoints=60,\n",
    "        n_post_intervention_timepoints=30,\n",
    "        global_mean=m,\n",
    "        global_scale=s,\n",
    "    )\n",
    "    data = simulate(cfg)\n",
    "    _ = plot(data, ax=ax, title=f\"Mean: {m}, Scale: {s}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "### Reproducibility\n",
    "\n",
    "In the above four panels, we can see that whilst the mean and scale of the underlying\n",
    "data generating process is varying, the functional form of the data is the same. This\n",
    "is by design to ensure that data sampling is reproducible. To sample a new dataset,\n",
    "you may either change the underlying seed in the config file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = Config(\n",
    "    n_control_units=10,\n",
    "    n_pre_intervention_timepoints=60,\n",
    "    n_post_intervention_timepoints=30,\n",
    "    seed=42,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "Reusing the same config file across simulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(ncols=2, figsize=(10, 3))\n",
    "for ax in axes:\n",
    "    data = simulate(cfg)\n",
    "    _ = plot(data, ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "Or manually specifying and passing your own pseudorandom number generator key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.RandomState(42)\n",
    "\n",
    "fig, axes = plt.subplots(ncols=2, figsize=(10, 3))\n",
    "for ax in axes:\n",
    "    data = simulate(cfg, key=rng)\n",
    "    _ = plot(data, ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "### Simulating an effect\n",
    "\n",
    "In the data we have seen up until now, the treated unit has been drawn from the same\n",
    "data generating process as the control units. However, it can be helpful to also\n",
    "inflate the treated unit to observe how well our model can recover the the true\n",
    "treatment effect. To do this, we simply compose our dataset with an `Effect` object.\n",
    "In the below, we shall inflate our data by 2%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "effect = StaticEffect(effect=0.02)\n",
    "inflated_data = effect(data)\n",
    "fig, (ax0, ax1) = plt.subplots(ncols=2, figsize=(10, 3))\n",
    "ax0 = plot(data, ax=ax0, title=\"Original data\")\n",
    "ax1 = plot(inflated_data, ax=ax1, title=\"Inflated data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "### More complex generation processes\n",
    "\n",
    "The example presented above shows a very simple stationary data generation process.\n",
    "However, we may make our example more complex by including a non-stationary trend to\n",
    "the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "trend_term = Trend(degree=1, coefficient=0.1)\n",
    "data_with_trend = effect(trend_term(data))\n",
    "ax = plot(data_with_trend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "trend_term = Trend(degree=2, coefficient=0.0025)\n",
    "data_with_trend = effect(trend_term(data))\n",
    "ax = plot(data_with_trend)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "We may also include periodic components in our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "periodicity = Periodic(amplitude=2, frequency=6)\n",
    "perioidic_data = effect(periodicity(trend_term(data)))\n",
    "ax = plot(perioidic_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "### Unit-level parameterisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampling_dist = norm(0.0, 1.0)\n",
    "intercept = UnitVaryingParameter(sampling_dist=sampling_dist)\n",
    "trend_term = Trend(degree=1, intercept=intercept, coefficient=0.1)\n",
    "data_with_trend = effect(trend_term(data))\n",
    "ax = plot(data_with_trend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampling_dist = poisson(2)\n",
    "frequency = UnitVaryingParameter(sampling_dist=sampling_dist)\n",
    "\n",
    "p = Periodic(frequency=frequency)\n",
    "ax = plot(p(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23",
   "metadata": {},
   "source": [
    "## Conclusions\n",
    "\n",
    "In this notebook we have shown how one can define their model's true underlying data\n",
    "generating process, starting from simple white-noise samples through to more complex\n",
    "example with periodic and temporal components, perhaps containing unit-level\n",
    "variation. In a follow-up notebook, we show how these datasets may be integrated with\n",
    "Amazon's own AZCausal library to compare the effect estimated by a model with the true\n",
    "effect of the underlying data generating process. A link to this notebook is\n",
    "[here](http://localhost:9998/causal-validation/examples/azcausal/)."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "title,-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
