{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Placebo Testing\n",
    "\n",
    "A placebo test is an approach to assess the validity of a causal model by checking if\n",
    "the effect can truly be attributed to the treatment, or to other spurious factors. A\n",
    "placebo test is conducted by iterating through the set of control units and at each\n",
    "iteration, replacing the treated unit by one of the control units and measuring the\n",
    "effect. If the model detects a significant effect, then it suggests potential bias or\n",
    "omitted variables in the analysis, indicating that the causal inference is flawed.\n",
    "\n",
    "A successful placebo test will show no statistically significant results and we may\n",
    "then conclude that the estimated effect can be attributed to the treatment and not\n",
    "driven by confounding factors. Conversely, a failed placebo test, which shows\n",
    "significant results, suggests that the identified treatment effect may not be\n",
    "reliable. Placebo testing is thus a critical step to ensure the robustness of findings\n",
    "in RCTs. In this notebook, we demonstrate how a placebo test can be conducted in\n",
    "`causal-validation`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azcausal.core.error import JackKnife\n",
    "from azcausal.estimators.panel.did import DID\n",
    "from azcausal.estimators.panel.sdid import SDID\n",
    "from scipy.stats import norm\n",
    "\n",
    "from causal_validation import (\n",
    "    Config,\n",
    "    simulate,\n",
    ")\n",
    "from causal_validation.data import DatasetContainer\n",
    "from causal_validation.effects import StaticEffect\n",
    "from causal_validation.models import AZCausalWrapper\n",
    "from causal_validation.plotters import plot\n",
    "from causal_validation.transforms import Trend\n",
    "from causal_validation.validation.placebo import PlaceboTest\n",
    "from causal_validation.transforms.parameter import UnitVaryingParameter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "## Data simulation\n",
    "\n",
    "To demonstrate a placebo test, we must first simulate some data. For the purposes of\n",
    "illustration, we'll simulate a very simple dataset containing 10 control units where\n",
    "each unit has 60 pre-intervention observations, and 30 post-intervention observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = Config(\n",
    "    n_control_units=10,\n",
    "    n_pre_intervention_timepoints=60,\n",
    "    n_post_intervention_timepoints=30,\n",
    "    seed=123,\n",
    ")\n",
    "\n",
    "TRUE_EFFECT = 0.05\n",
    "effect = StaticEffect(effect=TRUE_EFFECT)\n",
    "data = effect(simulate(cfg))\n",
    "ax = plot(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "## Model\n",
    "\n",
    "We'll now define our model. To do this, we'll use the synthetic\n",
    "difference-in-differences implementation of AZCausal. This implementation, along with\n",
    "any other model from AZCausal, can be neatly wrapped up in our `AZCausalWrapper` to\n",
    "make fitting and effect estimation simpler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AZCausalWrapper(model=SDID(), error_estimator=JackKnife())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "## Placebo Test Results\n",
    "\n",
    "Now that we have a dataset and model defined, we may conduct our placebo test. With 10\n",
    "control units, the test will estimate 10 individual effects; 1 per control unit when\n",
    "it is mocked as the treated group. With those 10 effects, the routine will then\n",
    "produce the mean estimated effect, along with the standard deviation across the\n",
    "estimated effect, the effect's standard error, and the p-value that corresponds to the\n",
    "null-hypothesis test that the effect is 0.\n",
    "\n",
    "In the below, we see that expected estimated effect is small at just 0.08.\n",
    "Accordingly, the p-value attains a value of 0.5, indicating that we have insufficient\n",
    "evidence to reject the null hypothesis and we, therefore, have no evidence to suggest\n",
    "that there is bias within this particular setup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = PlaceboTest(model, datasets=data).execute()\n",
    "result.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "## Model Comparison\n",
    "\n",
    "We can also use the results of a placebo test to compare two or more models. Using\n",
    "`causal-validation`, this is as simple as supplying a series of models to the placebo\n",
    "test and comparing their outputs. To demonstrate this, we will compare the previously\n",
    "used synthetic difference-in-differences model with regular difference-in-differences. In the previous placebo test you'll notice that the dataset in use was named `\"Dataset 0\"`. We can set the `name` property of our `Dataset` to more cleanly log the name of the data under consideration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.name = \"Simple\"\n",
    "did_model = AZCausalWrapper(model=DID())\n",
    "PlaceboTest([model, did_model], data).execute().summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "Sometimes, we may wish to compare multiple models across multiple datasets. Fortunately, this is as simple as providing the datasets as a list to `PlaceboTest`, much like the models we supplied in the previous cell. From here, `causal-validation` will go and conduct a placebo test for each pair of model and dataset. To see this, let us now synthesis a more complex dataset where the intercept and slope of each control unit vary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg2 = Config(\n",
    "    n_control_units=10,\n",
    "    n_pre_intervention_timepoints=60,\n",
    "    n_post_intervention_timepoints=30,\n",
    "    seed=42,\n",
    ")\n",
    "\n",
    "\n",
    "effect = StaticEffect(effect=TRUE_EFFECT)\n",
    "intercept = UnitVaryingParameter(sampling_dist=norm(0.0, 1.0))\n",
    "slope = UnitVaryingParameter(sampling_dist=norm(0.2, 0.05))\n",
    "trend = Trend(degree=1, coefficient=slope, intercept=intercept)\n",
    "complex_data = effect(trend(simulate(cfg2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "By default, the data will be named according to the index it was supplied, as seen in previous cells. However, it can be named by wrapping the datasets up in a `DatasetContainer` object and supplying the datasets' names as a list of strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = DatasetContainer([data, complex_data], names=[\"Simple\", \"Complex\"])\n",
    "PlaceboTest([model, did_model], datasets).execute().summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "custom_cell_magics": "kql"
  },
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
